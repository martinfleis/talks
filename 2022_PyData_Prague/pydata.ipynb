{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData Prague - A Gentle Introduction to Spatial Data in the Pandas Ecosystem\n",
    "\n",
    "**Martin Fleischmann**\n",
    "\n",
    "<sup>1</sup>Geographic Data Science Lab, University of Liverpool, UK<br>\n",
    "<sup>2</sup>Urban and Regional Laboratory, Charles University, CZ<br>\n",
    "<sup>3</sup>UrbanDataLab AG, Zürich, CH\n",
    "\n",
    "18/10/2022, Prague\n",
    "\n",
    "\"*Everything is related to everything else, but near things are more related than distant things*\" \n",
    "\n",
    "That is the first law of geography. But how do we apply it to data science? How do we ensure that our analysis has a spatial dimension and that it can be mapped? How can we combine data based on their location? Are there any spatial patterns?\n",
    "\n",
    "These are the questions you will be able to answer after a gentle introduction to spatial data science in the pandas ecosystem. We will start with a brief explanation of the key concepts like geometries and projections to introduce GeoPandas, a package that brings *geo* to pandas. Then we'll check how the ecosystem supporting GeoPandas looks like and what it offers, followed by a short excursion to the realm of spatial analytics using the packages from the PySAL (Python Spatial Analysis Library) project. We will be able to expand traditional exploratory data analysis with *spatial* using the *esda* package, interpolate data between different spatial units using the *tobler* package or analyse the structure of cities using *momepy*. Finally, when the data begin to look too large to work with, we switch to distributed dask-geopandas and wrap up our journey with spatial operations powered by Dask somewhere in the cloud.\n",
    "\n",
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with some demographic characteristics in Liverpool, borrowed from a [Geographic Data Science](https://darribas.org/gds_course/content/bB/lab_B.html) course by [Dani Arribas-Bel](http://twitter.com/darribas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop = pandas.read_csv(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_pop.csv\",  # path to the file\n",
    "    index_col=\"GeographyCode\",  # column to use as an index\n",
    ")\n",
    "liv_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPandas in action\n",
    "\n",
    "First, we need to read some data.\n",
    "\n",
    "### Reading files\n",
    "\n",
    "Assuming you have a file containing both data and geometry (e.g. GeoPackage, GeoJSON, Shapefile), you can read it using `geopandas.read_file()`, which automatically detects the filetype and creates a `GeoDataFrame`. This can use either `fiona` or `pyogrio` as an engine (as of GeoPandas 0.11) interfacing GDAL/OGR to do the heavy lifting. We use `pyogrio` as a newer, faster option.\n",
    "\n",
    "We will again borrow data from the [GDS course](https://darribas.org/gds_course/content/bC/lab_C.html#cities) we used before. This time we load the boundaries of Spanish cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = geopandas.read_file(\"https://ndownloader.figshare.com/files/20232174\", engine=\"pyogrio\")\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"geometry\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "To write a `GeoDataFrame` back to file use `GeoDataFrame.to_file()`. The file is format automatically inferred from the suffix, but you can specify your own with the `driver` keyword. When no suffix is given, GeoPandas expects you want a folder with ESRI Shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.to_file(\"cities.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometries\n",
    "\n",
    "Geometries within the *geometry* column are `shapely` objects. GeoPandas itself is not creating the object but leverages the existing ecosystem (note that there is a significant overlap of the team writing both to ensure synergy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.geometry.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0].wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But without an assigned CRS, we don't know where on the Earth this shape lies. Therefore, each geometry column has (optionally) assigned one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs.is_geographic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the whole ecosystem comes together.\n",
    "\n",
    "### Simple accessors and methods\n",
    "\n",
    "Now we have our `GeoDataFrame` and can start working with its geometry. \n",
    "\n",
    "Since there was only one geometry column in the Spanish cities dataset, this column automatically becomes the _active_ geometry and spatial methods used on the `GeoDataFrame` will be applied to the `\"geometry\"` column.\n",
    "\n",
    "#### Measuring area\n",
    "\n",
    "To measure the area of each polygon, access the `GeoDataFrame.area` attribute, which returns a `pandas.Series`. Note that `GeoDataFrame.area` is just `GeoSeries.area` applied to the _active_ geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"area\"] = cities.area\n",
    "cities[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting polygon boundary and centroid\n",
    "\n",
    "To get the boundary of each polygon (LineString), access the `GeoDataFrame.boundary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"boundary\"] = cities.boundary\n",
    "cities[\"boundary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have saved boundary as a new column, we now have two geometry columns in the same `GeoDataFrame`.\n",
    "\n",
    "We can also create new geometries, which could be, for example, a buffered version of the original one (i.e., `GeoDataFrame.buffer(10)`) or its centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"centroid\"] = cities.centroid\n",
    "cities[\"centroid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring distance\n",
    "\n",
    "We can also measure how far each centroid is from the first centroid location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point = cities[\"centroid\"].iloc[0]\n",
    "cities[\"distance\"] = cities[\"centroid\"].distance(first_point)\n",
    "cities[\"distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point.wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"centroid\"].distance(first_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `geopandas.GeoDataFrame` is a subclass of `pandas.DataFrame`, so we have all the pandas functionality available to use on the geospatial dataset — we can even perform data manipulations with the attributes and geometry information together.\n",
    "\n",
    "For example, to calculate the average of the distances measured above, access the `\"distance\"` column and call the `mean()` method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"distance\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"distance\"].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Making maps\n",
    "\n",
    "GeoPandas can also plot maps, so we can check how the geometries appear in space. To plot the active geometry, call `GeoDataFrame.plot()`. To color code by another column, pass in that column as the first argument. In the example below, we plot the active geometry column and color code by the `\"area\"` column. We also want to show a legend (`legend=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.plot(\"area\", legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Other resources for plotting\n",
    "\n",
    "Want to know more on static plots? Check [this chapter](https://darribas.org/gds_course/content/bC/lab_C.html#styling-plots) of the GDS course or [the GeoPandas documentation](https://geopandas.org/en/stable/docs/user_guide/mapping.html).\n",
    "</div>\n",
    "\n",
    "You can also explore your data interactively using `GeoDataFrame.explore()`, which behaves in the same way `plot()` does but returns an interactive (leaflet.js) map instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.explore(\"area\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching the active geometry (`GeoDataFrame.set_geometry`) to centroids, we can plot the same data using point geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"centroid\")\n",
    "cities.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also layer both `GeoSeries` on top of each other. We just need to use one plot as an axis for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cities[\"geometry\"].explore()\n",
    "cities[\"centroid\"].explore(m=m, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the active geometry back to the original `GeoSeries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial predicates\n",
    "\n",
    "Spatial predicates tell us what is the spatial relation between two geometries. Are they equal, do they intersects, overlap, is one wihtin another?\n",
    "\n",
    "For this part we use a toy datasets that come with GeoPandas, so we just need to retrive their location within the package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.datasets.get_path('naturalearth_lowres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "world_cities = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = world_countries.explore()\n",
    "world_cities.explore(m=m, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create some small toy spatial objects:\n",
    "\n",
    "A polygon <small>(note: we use `.item()` here to to extract the scalar geometry object from the GeoSeries of length 1)</small>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium = world_countries.loc[world_countries['name'] == 'Belgium', 'geometry'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = world_cities.loc[world_cities['name'] == 'Paris', 'geometry'].item()\n",
    "brussels = world_cities.loc[world_cities['name'] == 'Brussels', 'geometry'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a linestring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "line = LineString([paris, brussels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize those 4 geometry objects together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.GeoSeries([belgium, paris, brussels, line], crs=world_cities.crs).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can recognize the abstract shape of Belgium.\n",
    "\n",
    "Brussels, the capital of Belgium, is thus located within Belgium. This is a spatial relationship, and we can test this using the individual shapely geometry objects as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the reverse, Belgium contains Brussels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(brussels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, Paris is not located in Belgium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(belgium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The straight line we draw from Paris to Brussels is not fully located within Belgium, but it does intersect with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.intersects(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial relationships with GeoDataFrames\n",
    "\n",
    "The same methods that are available on individual `shapely` geometries as we have seen above, are also available as methods on `GeoSeries` / `GeoDataFrame` objects.\n",
    "\n",
    "For example, if we call the `contains` method on the world dataset with the `paris` point, it will do this spatial check for each country in the `world` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries.contains(paris).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the above gives us a boolean result, we can use that to filter the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries[world_countries.contains(paris)].explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do the same based on a query over the spatial index. Custom queries on spatial index using `query` and esp. `query_bulk` are often much faster but are also considered an advanced usage. Since GeoPandas wraps them in spatial joins covering most of the cases, you may not even need to access `sindex` directly yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries.iloc[world_countries.sindex.query(paris, \"within\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial join\n",
    "\n",
    "One of he most typical geospatial tasks is a spatial join. Let's go back to our dataset with the Spanish city boundaries and try to figure out which of these cities fall into Catalonia region and which province they belong to.\n",
    "\n",
    "First, we need a data representing Catalonia. We get one directly from the Catalonian open data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalonia = geopandas.read_file(\n",
    "    \"https://github.com/martinfleis/opengeohub2022-tutorial/raw/main/catalonia.gpkg\",\n",
    ")\n",
    "catalonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the CRS, because for spatial join, we need to be sure that both GeoDataFrames are using the same (but don't worry, GeoPandas would warn you in case of a CRS mismatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this one is different, we can re-project the geometries to the CRS of `cities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia = catalonia.to_crs(cities.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.crs.equals(cities.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the spaital join using the `sjoin` method. That by default uses the `intersects` predicate but you can use any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia = cities.sjoin(catalonia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cities_within_catalonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.explore(\n",
    "    \"CAPPROV\",\n",
    "    tiles=\"Stamen Toner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GeoDataFrames are still based on pandas DataFrames, we can readily use pandas functionality, like `groupby` on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.groupby(\"nom_prov\").area.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay\n",
    "\n",
    "In some cases, we may want to create new geometries based on their spatial relationships between existing geometries. We call these _overlay_ operations.\n",
    "\n",
    "Let's assume that we are interested in areas that are 10km around a centroid of each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_centroids = cities['centroid'].buffer(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_centroids.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can ask for an intersection between the buffer and city boundaries.\n",
    "\n",
    "![intersection](https://geopandas.org/en/stable/_images/binary_geo-intersection.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"intersection\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we may want to do the union of the two to get area covered either by distance or the boundary.\n",
    "\n",
    "![union](https://geopandas.org/en/stable/_images/binary_geo-union.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"union\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or do the difference. Find all parts of boundaries that are further away than 10km from each centroid.\n",
    "\n",
    "![difference](https://geopandas.org/en/stable/_images/binary_geo-difference.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"difference\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we may as which parts areas are either wihtin 10km or wihtin a boundary but not both.\n",
    "\n",
    "![difference](https://geopandas.org/en/stable/_images/binary_geo-symm_diff.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_centroids.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"symmetric_difference\").explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.overlay(cities).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ecosystem\n",
    "\n",
    "We can now move beyond GeoPandas, because while being useful itself, its main benefit is that it enables others to build on top of a robust basis. We can take an example of PySAL, Python Spatial Analysis Library. PySAL is a federation of 21 individual packages covering everything from basic spatial weights matrices to spatial regression, optimisation, point pattern analysis or dasymetric mapping.\n",
    "\n",
    "Today, we will look at two of them to learn how to work with spatial weights and how to measure local index of spatial autocorrelatoin (LISA).\n",
    "\n",
    "Let's go back to our LSOA-based data from Liverpool. This time, we load the geometries using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = geopandas.read_file(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_lsoas.gpkg\",\n",
    ")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial weights\n",
    "\n",
    "Spatial weights can be created in many ways based on many conditions. We are now intersted in the most common one - contiguity. We simply want to encode, which geometries are neighbours of which.\n",
    "\n",
    "To generate such a matrix, we can use the `weights` module of `libpysal` and its `Queen` contiguity implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal import weights\n",
    "\n",
    "w_queen = weights.Queen.from_dataframe(liv_lsoa, idVariable=\"LSOA11CD\")\n",
    "w_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have used the LSOA code to encode the spatial weights. To make it a bit easier below, let's set the same variable as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.set_index(\"LSOA11CD\")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore what `w_queen` object actually contains. We can pick one LSOA, say `E01006690` and check its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen[\"E01006690\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number `1.0` encodes the strength, because weights can be more complex than simple boolean \"is neighbor\" or \"is not\". It can potentially be weighted based on the lenght of the common boundary.\n",
    "\n",
    "We can also quickly check how many neighbours it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.cardinalities[\"E01006690\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it is more or less than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.mean_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_queen[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or all neighbours within 2 kilometres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_2km = weights.DistanceBand.from_dataframe(liv_lsoa, threshold=2000, ids=liv_lsoa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_2km[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial lag\n",
    "\n",
    "Now, remember that we also had some data for these areas. Let's compare the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has geometries but no data, the other has data but no geometries. But both share the LSOA code we can use to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.merge(liv_pop, left_on=\"LSOA11CD\", right_on=\"GeographyCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the very useful things we can do with spatial weights is to calculate a spatial lag. That is, in principle, a mean of values from neighbouring geometries.\n",
    "\n",
    "We can measure it easily using `lag_spatial` function. But before that, we need to transform the weights so the all weights (the numbers) for each geometry sum up to one. Otherwise we would measure the sum of instead of mean.\n",
    "\n",
    "Weights before the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_queen.weights['E01006512']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row-wise transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.transform = \"R\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights after the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.weights['E01006512']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can measure the lag. For example of the `\"Middle East and Asia\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen_score = weights.lag_spatial(w_queen, liv_lsoa[\"Middle East and Asia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen_score[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign it to the dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia lagged\"] = w_queen_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran plot\n",
    "\n",
    "With the spatial lag, we can start asking some spatial questions. Like, is there a spatial autocorrelation? The simplest way of getting a sense on that is to plot the original variable against its spatial lag, so called Moran plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.plot.scatter(\n",
    "    \"Middle East and Asia\", \"Middle East and Asia lagged\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a relationship between the two, we can assume spatial autocorrelation of the variable. And here it seems that there is a strong one.\n",
    "\n",
    "### LISA\n",
    "\n",
    "We can explore that further, using the Local Indicator of Spatial Autocorrelation (LISA), implemented in another of PySAL's packages called `esda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran_Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do the actual measuring, we should normalise the values as some of the LSOAs have larger total population than the others and it would skew the output. We can rather look at proportions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia proportion\"] = (\n",
    "    liv_lsoa[\"Middle East and Asia\"] / liv_lsoa.sum(axis=1, numeric_only=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our existing spatial weights, pass the variable and measure the LISA based on Moran's I using the `Moran_Local` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc = Moran_Local(liv_lsoa[\"Middle East and Asia proportion\"], w_queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now explore the object. \n",
    "\n",
    "First, a LISA quadrant encoding if the geometry has high values and is surrounded by other of high values or any other combination of high and low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a simulated P value indicating significance of the result for each geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is enough for us to plot the result and see whether there are any hotspots where Asian and Middle East population tend to live or any cold spots they are not present in.\n",
    "\n",
    "For easier reading we can relabel the quadrants with self-explanatory labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_labels = {\n",
    "    1: \"High-high\",\n",
    "    2: \"Low-high\",\n",
    "    3: \"Low-low\",\n",
    "    4: \"High-low\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can just assign the quadrants and P-values as columns, filter based on significance and look at the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"moran_q\"] = moran_loc.q\n",
    "liv_lsoa[\"moran_q\"] = liv_lsoa[\"moran_q\"].map(moran_labels)\n",
    "liv_lsoa[\"moran_p\"] = moran_loc.p_sim\n",
    "liv_lsoa.loc[liv_lsoa[\"moran_p\"] > 0.05, \"moran_q\"] = None  # filter by significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"moran_q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quilckly compare the quadrants to the actual distribution, to see if it \"makes sense\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"Middle East and Asia proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to take these clusters and get only their boundaries. In practice, we want to _union_ all the geometries belonging to a single class. That is where GeoPandas is comes useful again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoPandas has a built in method for this spatial groupby, called `dissolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants = liv_lsoa.dissolve(\"moran_q\")\n",
    "quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have mutli polygons, one geometry per class. Let's say we want each location on its own. We want to _explode_ the geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants_individual = quadrants.explode(index_parts=True)\n",
    "quadrants_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrants_individual.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Areal interpolation\n",
    "\n",
    "Sometimes we need to move data from one layer to another but they are not matching. That is when areal interpolation comes in. PySAL offers a range solutions within a `tobler` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tobler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = geopandas.read_file(\"https://ndownloader.figshare.com/files/20460645\")\n",
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precincts = geopandas.read_file(\"https://ndownloader.figshare.com/files/20460549\") \n",
    "precincts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = tracts.explore(tooltip=False, style_kwds=dict(fill=False))\n",
    "precincts.explore(color='red', m=m, tooltip=False, style_kwds=dict(fill=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = tracts.to_crs(precincts.crs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = tobler.area_weighted.area_interpolate(tracts, precincts, intensive_variables=['pct Youth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates.explore(\"pct Youth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Field-specific applications\n",
    "\n",
    "Up until now, all you've seen was useful in a wide range of geographic use cases. But there are also specific targeted packages, even within PySAL. Like `momepy`, designed to udnerstand urban environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import momepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going big\n",
    "\n",
    "We are entering the last part of the tutorial. This even may be a homework for you, depends on the time :).\n",
    "\n",
    "Everything we ave used so far was running in a single thread on your computers. Given you probably have 4 or more cores on your CPU, only one was running, other were idle.\n",
    "\n",
    "For these situations, and for those when your data don't fit your RAM, the Python ecosystem offers a solution called Dask and the combination of Dask and GeoPandas called Dask-GeoPandas. \n",
    "\n",
    "### What is Dask?\n",
    "\n",
    "From the docs:\n",
    "\n",
    "> Dask provides advanced parallelism and distributed out-of-core computation with a dask.dataframe module designed to scale pandas. Since GeoPandas is an extension to the pandas DataFrame, the same way Dask scales pandas can also be applied to GeoPandas.\n",
    "\n",
    "For more, see the [Dask tutorial](https://tutorial.dask.org).\n",
    "\n",
    "### Dask-GeoPandas\n",
    "\n",
    "We use the power of Dask and GeoPandas to run geospatial processing in parallel right now, but you can even use it to run the code on a distributed cluster and even out-of-core, when your data don't fit the memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That in practice means that we split the GeoDataFrame into multiple partitions and each is processed by a single thread. And some communication between the workers that is controlled by Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf = dask_geopandas.from_geopandas(liv_lsoa, npartitions=4)\n",
    "liv_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is done lazily as Dask expects the data may be too large, we don't see the values here. For now.\n",
    "\n",
    "The API works nearly exactly the same as we have seen above. It is just split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter = liv_ddf.length\n",
    "perimeter.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf[\"perimeter\"] = perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf['centroid'] = liv_ddf.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `compute()`, Dask runs all the tasks and returns the result. Same we would get from GeoPandas, just a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = liv_ddf.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How faster? Depends on the machine and operation, of course, but here is a simple example.\n",
    "\n",
    "The GeoDataFrame used above is a bit small to see any benefit from parallelization using dask (as the overhead of the task scheduler is larger than the actual operation on such a tiny dataframe), so let’s create a bigger point GeoSeries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "N = 10_000_000\n",
    "points = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.points_from_xy(numpy.random.randn(N), numpy.random.randn(N))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And creating the dask-geopandas version of this series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpoints = dask_geopandas.from_geopandas(points, npartitions=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single polygon for which we will check if the points are located within this polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "box = shapely.geometry.box(0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compare the time it takes to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit points.within(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dpoints.within(box).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "This tutorial is more closely or more loosely based on the following resources:\n",
    "\n",
    "- [Introduction to GeoPandas](https://geopandas.org/en/latest/getting_started/introduction.html) by Martin Fleischmann and GeoPandas contributors\n",
    "- [GeoPandas API reference](https://geopandas.org/en/stable/docs/reference.html) by GeoPandas contributors\n",
    "- [Getting started (pandas)](https://pandas.pydata.org/docs/getting_started/index.html) by Stijn Van Hoey and pandas contributors\n",
    "- Arribas-Bel, (2019). A course on Geographic Data Science. Journal of Open Source Education, 2(14), 42, [https://doi.org/10.21105/jose.00042](https://doi.org/10.21105/jose.00042)\n",
    "- Introduction to geospatial data analysis with GeoPandas and the PyData stack bu Joris van den Bossche (https://github.com/jorisvandenbossche/geopandas-tutorial)\n",
    "- Fleischmann, M., Feliciotti, A. and Kerr, W. (2022), Evolution of Urban Patterns: Urban Morphology as an Open Reproducible Data Science. Geogr Anal, 54: 536-558. [https://doi.org/10.1111/gean.12302](https://doi.org/10.1111/gean.12302)\n",
    "- datos.gob.es [Administrative province boundaries in Catalonia](https://datos.gob.es/en/catalogo/a09002970-limites-administativos-provinciales-de-catalunya)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1b2c984ad473d756980598d6fae8279815dc9c89a9d51a262cfb04eba7ee8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
